apply plugin: 'scala'
apply plugin: 'com.github.johnrengelman.shadow'

compileScala.options.encoding = 'UTF-8'

// fix scala+java mix to all use compileScala which uses correct dependency order
sourceSets.main.scala.srcDir "src/main/java"
sourceSets.main.java.srcDirs = []

dependencies {
  compile 'org.scala-lang:scala-library:' + scalaVersion
  compile 'org.scala-lang:scala-reflect:' + scalaVersion
  compile 'org.scala-lang:scala-compiler:' + scalaVersion
  compile group: 'com.databricks', name: 'spark-csv_2.10', version: '1.2.0'
  compile project(':snappy-core_' + scalaBinaryVersion)
  if (new File(rootDir, "snappy-spark/build.gradle").exists()) {
    compile project(':snappy-spark:snappy-spark-repl_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-yarn_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-graphx_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-hive-thriftserver_' + scalaBinaryVersion)
  } else {
    compile 'org.apache.spark:snappy-spark-repl_' + scalaBinaryVersion + ':' + sparkVersion
    compile 'org.apache.spark:snappy-spark-yarn_' + scalaBinaryVersion + ':' + sparkVersion
    compile 'org.apache.spark:snappy-spark-graphx_' + scalaBinaryVersion + ':' + sparkVersion
    compile 'org.apache.spark:snappy-spark-hive-thriftserver_' + scalaBinaryVersion + ':' + sparkVersion
  }
  if (new File(rootDir, "snappy-store/build.gradle").exists()) {
    compile project(':snappy-store:gemfirexd:client')
    compile project(':snappy-store:gemfirexd:core')
    compile project(':snappy-store:gemfirexd:tools')

    testCompile project(path: ':snappy-store:gemfirexd:tools', configuration: 'testOutput')
  } else {
    compile files("${rootDir.getAbsolutePath()}/local-repo/gemfirexd-client-${gemfireXDVersion}.jar")
    compile files("${rootDir.getAbsolutePath()}/local-repo/gemfirexd-${gemfireXDVersion}.jar")
    compile files("${rootDir.getAbsolutePath()}/local-repo/gemfirexd-tools-${gemfireXDVersion}.jar")
  }

  if (new File(rootDir, "spark-jobserver/build.gradle").exists()) {
    compile project(':spark-jobserver')
  } else {
    compile files("${rootDir.getAbsolutePath()}/local-repo/spark-jobserver-1.6.0-SNAPSHOT.jar")
  }

  testCompile project(path: ':snappy-core_' + scalaBinaryVersion, configuration: 'testOutput')
  testCompile 'org.scalatest:scalatest_' + scalaBinaryVersion + ':2.2.1'

  testRuntime 'org.pegdown:pegdown:1.1.0'
}

testClasses.doLast {
  copyTestsCommonResources(buildDir)
}

test.dependsOn ':cleanJUnit'
scalaTest {
  // This property is a temporary fix for scala tests to not use default-persistent
  // connection property in SnappyHiveCatalog
  systemProperty "scalaTest", "true"
  dependsOn ':cleanScalaTest'
  doFirst {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
  doLast {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
}
check.dependsOn ':product'

shadowJar {
  zip64 = true

  //inputs.files jar.outputs.files
  //outputs.file "${buildDir}/libs/${archiveName}"

  mergeServiceFiles {
    exclude 'META-INF/*.SF'
    exclude 'META-INF/*.DSA'
    exclude 'META-INF/*.RSA'
  }
  append('META-INF/services/org.apache.hadoop.fs.FileSystem')
  append('reference.conf')
  exclude 'org/datanucleus/**'
  exclude 'log4j.properties'

  /*
  from {
    def allJars = new HashSet<File>()
    project(":snappy-tools_${scalaBinaryVersion}").configurations.runtime.each {
      allJars.add(it)
    }
    allJars.collect {
      it.isDirectory() ? it : zipTree(it).matching {
        exclude {
          it.path.contains('META-INF')
        }
      }
    }
  }
  */

  manifest {
    attributes(
      "Manifest-Version"  : "1.0",
      "Created-By"        : System.getProperty("user.name"),
      "Title"             : rootProject.name,
      "Version"           : version,
      "Vendor"            : "Snappy Data, Inc."
    )
  }
}
